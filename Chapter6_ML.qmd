---
title: "Chapter 6 ML"
author: "Rchemist"
format: html
editor: visual
---

R로 하는 머신 러닝.

R로 머신러닝을 수행할 수 있는 방법은 여러 가지가 있습니다.

사실 인공지능 분야에서 R보다 더 유명한 것은 Python일 것입니다. Python에는 scikit-learn이라고 하는 훌륭한 프레임워크가 존재하기 때문입니다.

그렇다고 R에서 머신러닝을 할 수 없는 것은 아닙니다. R 역시 Python의 scikit-learn처럼 머신러닝을 하기 위한 다양한 [패키지 세트]{.underline}들이 존재합니다. 대표적으로는 `caret`, `tidymodels`, `mlr3` 등이 있습니다.

그러나 이번 과정에서는 특정 머신러닝 패키지를 완전히 이해하는 데 초점을 마추지 않았습니다. R에서 머신러닝을 어떻게 수행하는지 간단하게 살펴보기 위해 기초적인 내용만 소개하도록 하겠습니다.

> 머신러닝 패키지 세트에 대한 내용은 추후 강의에서 올리도록 하겠습니다!

------------------------------------------------------------------------

## 1. 데이터 전처리

데이터 전처리(Data preprocessing)이란 머신러닝 이전에 데이터를 정제하고 가공하는 것을 의미합니다. 머신러닝에서 모델링 이전에 전처리를 하는 이유는 간단합니다. 모델로부터 더욱 높은 성능을 끌어내기 위함입니다.

```{r}
target <- names(dt4[,sapply(dt4, \(x) any(x %in% c('Yes','No'))),with=F])

dt4[,(target):=lapply(.SD, \(x)ifelse(x=='No',0,1)),.SDcols=target]

dt4[,Race := ifelse(Race %like% 'Indian','Indian',Race)]
dt4[,GenHealth := ifelse(GenHealth=='Very good','Very_good',GenHealth)]
dt4[,AgeCategory:=ifelse(AgeCategory %like% '80','Over80',AgeCategory)]
```

### 1) train test split

```{r}
library(caret)
set.seed(2022)
train.idx <- createDataPartition(dt4$HeartDisease,p=0.7)
train <- dt4[train.idx$Resample1]
test <- dt4[-train.idx$Resample1]
```

### 2) outlier

```{r}
target <- c('BMI','SleepTime')
train[,(target):=lapply(.SD, \(x) ifelse(x<quantile(x, prob=.25, na.rm=T)-1.5*IQR(x,na.rm=T) | x> quantile(x,prob=.75, na.rm=T) + 1.5*IQR(x, na.rm=T),NA,x)),.SDcols=target]

checkOutlier <- function(x){
  y <- ifelse(x<quantile(x, prob=.25, na.rm=T)-1.5*IQR(x,na.rm=T) | x> quantile(x,prob=.75, na.rm=T) + 1.5*IQR(x, na.rm=T),NA,x)
  return(y)
}
test[,(target):=lapply(.SD, checkOutlier),.SDcols=target]

```

### 3) imputation

-   single imputation: 단일 값으로 결측치 처리

    ```{r}
    med <- preProcess(train,method = 'medianImpute')
    head(predict(med, train))
    ```

-   multiple imputation: 여러 값으로 결측치 처리합니다.

    `caret`에서 multiple imputation을 지원하는 방법은 knnImpute와 bagImpute가 있습니다. imputation 실행을 위해 필요한 패키지가 설치되어 있지 않은 경우, 패키지를 요구하는 에러 메시지가 뜨게 됩니다.

    -   `preProcess()` 에서 `method='knnImpute'`

    -   `preProcess()` 에서 `method='bagImpute'`

        ```{r}
        knnImp <- preProcess(train, method = 'knnImpute')
        # install.packages('RANN')
        train_scale <- predict(knnImp, train)
        ```

imputation의 경우 single imputation의 방법이 가장 간단하고 빠르다는 장점이 있지만, multiple imputation에 비해 부정확하다는 단점이 있습니다.

+---------------------+---------------------------------------------------------------+--------+----------------------------------+--------------+
| method              | 설명                                                          | 장점   | 단점                             | 예시         |
+:===================:+:=============================================================:+:======:+:================================:+:============:+
| single imputation   | 단일한 값으로 결측치를 채움                                   | 간단함 | 다소 편향(bias)이 발생할 수 있음 | 평균, 중앙값 |
|                     |                                                               |        |                                  |              |
|                     |                                                               | 빠름   |                                  |              |
+---------------------+---------------------------------------------------------------+--------+----------------------------------+--------------+
| multiple imputation | 결측치가 있는 변수 이외의 다른 특성 또한 고려해 결측치를 채움 | 정확함 | 다소 시간이 오래 걸림            | mice         |
+---------------------+---------------------------------------------------------------+--------+----------------------------------+--------------+

### 4) Feature Scaling

연속형 변수들에 대해 스케일링을 하는 방법에는 크게 정규화(Normalization)과 표준화(Standardization)이 있습니다.

::: callout-tip
## 스케일링을 해야 하는 이유는?

각 변수(feature) 마다 다른 범위의 값들을 갖고 있습니다. 예를 들어, 나이는 보통 0\~100의 범위를 갖는 반면, 월별 소득은 0\~10,000,000원 혹은 더 큰 범위를 가질 수 있습니다. 이처럼 월별 소득은 키보다 훨씬 넓은 범위의 값을 가질 수 있습니다.

> 이 피처들을 그대로 활용한다면, 소득은 큰 값 때문에 결과에 더 큰 영향을 미치게 됩니다. 그렇다고 해서 소득이 반드시 나이보다 더 중요한 피처라고는 확정지을 수 없습니다.
>
> 따라서 우리는 스케일링을 통해 각 피처들의 단위와 분포를 동일하게 변경하여 모든 피처들이 결과에 미치는 영향을 동일선상에서 비교할 수 있게끔 만들어 주어야 합니다.
:::

```{r}
require(data.table)
require(dplyr)
require(ggplot2)
melt(as.data.table(mtcars), id.vars = 'vs', measure.vars=c('mpg','drat','disp','hp')) %>% ggplot(aes(x=variable,y=value)) + 
  geom_boxplot() +
  theme_classic()
```

```{r}
target <- c('mpg','drat','disp','hp')
mtcars2 <- as.data.table(mtcars)
mtcars2[,(target):=lapply(.SD,\(x) (x-min(x))/(max(x)-min(x))),.SDcols=target]
mtcars3 <- melt(mtcars2, id.vars = 'vs', measure.vars=c('mpg','drat','disp','hp')) 
mtcars3 %>% 
  ggplot(aes(x=variable,y=value)) + 
  geom_boxplot() +
  theme_classic()
```

#### a. 정규화 (Normalization)

정규화는 연속형 변수의 범위를 최소 0, 최대 1인 분포로 변경하는 방법입니다.

$$
X'= \begin {matrix}X-X_{min} \over X_{max}-X_{min} \end {matrix}
$$

정규화는 해당 변수의 값에서 그 변수의 최솟값을 뺀 값을 변수의 최댓값-최솟값으로 나누어 주면 됩니다.

정규화를 수행하기 위해서 임의의 함수를 만들 수 있습니다.

```{r}
normalization <- function(x){
  y <- (x-min(x))/(max(x)-min(x))
  return(y)
}
```

#### b. 표준화 (Standardization)

표준화는 연속형 변수를 평균이 0, 표준편차가 1인 분포를 따르도록 변경하는 방법입니다.

$$
X' = \begin {matrix}X-\mu\over \sigma \end{matrix}
$$

표준화를 수행하기 위해서 `scale()` 함수를 이용하거나 직접 표준화 함수를 구현할 수 있습니다.

```{r}
scale(x, center=T, scale = T)
standardization <- function(x){
  y <- (x-mean(x,na.rm=T))/sd(x,na.rm=T)
  return(y)
}
```

### 5) dummy

dummy란 여러 개의 범주를 갖는 범주형 변수(categorical)를 0과 1 값을 갖는 여러 개의 변수로 변형하는 것을 말합니다.

예를 들어

```{r}
train[,table(Race)]
```

인종 (Race)은 총 6가지의 범주를 가진 column입니다. Race를 dummy 처리하면 다음과 같습니다.

```{r}
train_dummy <- dummy_cols(train,select_columns = 'Race',remove_selected_columns = T)
train_dummy[,.SD,.SDcols=patterns('Race_')]
```

위에서 볼 수 있듯이, Race의 범주들이 0과 1을 갖는 하나의 column으로 변경된 것을 알 수 있습니다.

```{r}
library(fastDummies)
train_dummy <- dummy_cols(train, select_columns = c('AgeCategory','GenHealth','Race'),remove_selected_columns = T)

```

```{r}
target <- c('mpg','drat','disp','hp')
mtcars2 <- as.data.table(mtcars)
mtcars2[,(target):=lapply(.SD,\(x) (x-mean(x))/(sd(x))),.SDcols=target]
mtcars3 <- melt(mtcars2, id.vars = 'vs', measure.vars=c('mpg','drat','disp','hp')) 
mtcars3 %>% 
  ggplot(aes(x=variable,y=value)) + 
  geom_boxplot() +
  theme_classic()
```

::: callout-note
데이터 전처리에서 정답은 존재하지 않습니다. 다양한 전처리를 통해 모델링을 하고 성능을 평가했을 때, 가장 높은 성능을 내는 방법이 가장 좋은 전처리 방법입니다!
:::

## 2. 모델링

모델링이란 알고리즘에 훈련 데이터를 투입하여 학습시키는 것을 의미합니다.

머신러닝에는 다양한 알고리즘이 존재합니다. 우리는 그 중에서도 대표적인 알고리즘 3가지를 배워보도록 하겠습니다.

```{r}

```

### 1) 로지스틱 회귀분석

```{r}

```

### 2) 랜덤 포레스트

```{r}

```

### 3) XGBoost

```{r}

```

## 3. 성능 평가

### 1) confusion matrix

```{r}

```

### 2) AUROC

### 3) AUPRC

precision recall curve의

그렇다면 언제 AUPRC를 사용할까요? target의 불균형이 심한 데이터를 예측했을 때 AUPRC를 함께 보여주는 것이 좋습니다. 실제로 불균형이 심한 데이터의 경우라고 하더라도 AUROC는 높게 나오곤 합니다.

## 셀프 과제

```{r}
dt6 <- fread('csv/6주차_cardio_train.csv')
dt6 %>% head()
```

### 1) 데이터 준비하기

------------------------------------------------------------------------

### 2) 데이터 전처리

2-1. 과제 데이터를 train 데이터, test 데이터로 나누세요. (seed:2022)

```{r}

```

2-2. IQR 방법을 이용하여 train 데이터와 test 데이터의 이상치(outlier)를 제거하세요.

```{r}

```

2-3. train 데이터와 test 데이터의 결측치(`NA`)를 imputation 하세요.

-   single imputation 또는 multiple imputation 사용

```{r}

```

2-4. train 데이터와 test 데이터의 연속형 응답 분포는 스케일링(Scaling)를, 범주형 변수는 dummy 처리하세요

```{r}

```

-   scaling: 표준화 또는 정규화 사용

```{r}

```

-   dummy: `fastDummies` 패키지 활용

```{r}

```

------------------------------------------------------------------------

### 3) 모델링

3-1. 3가지 종류의 알고리즘을 이용하여 logistic regression, random forest, xgboost 3가지의 모델을 학습시킨 후, test 데이터로 예측값을 만드세요.

```{r}

```

------------------------------------------------------------------------

### 4) 모델 성능 평가

4-1. `caret` 패키지의 `confusionMatrix()` 함수를 이용하여 각 알고리즘별 성능을 비교하세요.

```{r}

```

4-2. 각 알고리즘에서 학습에 중요하게 작용한 변수 6개를 출력하세요.

```{r}

```

4-3. `pROC` 패키지를 이용하여 AUC를 계산하고, ROC curve를 그리세요.

```{r}

```

------------------------------------------------------------------------

1.  전처리

#### a. train test split

#### b. outlier

smoke, alco, active, cardio, gender 등 binary 또는 factor 변수 제외하고

#### c. imputation

#### d. scaling

#### e. dummy
